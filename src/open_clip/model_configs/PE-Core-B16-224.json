{
    "embed_dim": 768,
    "quick_gelu": false,
    "vision_cfg": {
        "image_size": 224,
        "patch_size": 16,
        "layers": 12,
        "width": 768,
        "output_dim": 1024,
        "heads": 12,
        "mlp_ratio": 4.0,
        "pool_type": "attn",
        "use_cls_token": true
    },
    "text_cfg": {
        "context_length": 32,
        "vocab_size": 49408,
        "width": 1024,
        "heads": 16,
        "layers": 24
    }
}
